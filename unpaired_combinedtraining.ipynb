{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import json\n",
    "import nibabel as nib\n",
    "import sys\n",
    "import glob\n",
    "import csv\n",
    "import struct\n",
    "import json\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "\n",
    "\n",
    "from networks import RegModel,ShufflePermutation\n",
    "\n",
    "from utils import *\n",
    "\n",
    "if is_notebook():\n",
    "    from tqdm.notebook import tqdm, trange\n",
    "else:\n",
    "    from tqdm import tqdm, trange\n",
    "\n",
    "\n",
    "#from meidic_vtach_utils.run_on_recommended_cuda import get_cuda_environ_vars as get_vars\n",
    "#os.environ.update(get_vars('*'))\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"10\"\n",
    "\n",
    "skip_stage = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_seg(task_name, split ='train'):\n",
    "    if task_name == 'AbdomenCTCT':\n",
    "        with open('data_compressed/AbdomenCTCT/AbdomenCTCT_dataset.json') as f:\n",
    "            dataset=json.load(f)\n",
    "\n",
    "        image_shape=dataset['tensorImageShape']['0']\n",
    "        num_labels=len(dataset['labels']['0'])\n",
    "        H,W,D=image_shape\n",
    "\n",
    "        if split == 'train':\n",
    "            mode = 'Tr'\n",
    "            cases = [str(x).zfill(4) for x in sorted(list(range(31)[2::3])+list(range(31)[3::3]))]\n",
    "            num_train=len(cases)\n",
    "            labels = torch.zeros(num_train,num_labels,H//2,W//2,D//2).pin_memory()\n",
    "            for i,case in tqdm(enumerate(cases),total=num_train):\n",
    "                labels[i] = F.avg_pool3d(F.one_hot(torch.from_numpy(nib.load(f'data_compressed/AbdomenCTCT/labelsTr/AbdomenCTCT_{case}_0000.nii.gz').get_fdata()).long().unsqueeze(0),num_labels).permute(0,4,1,2,3),2)\n",
    "        \n",
    "        elif split == 'val':\n",
    "            mode = 'Tr'\n",
    "            cases = [str(x).zfill(4) for x in list(range(31)[1::3])]\n",
    "            num_train=len(cases)\n",
    "            labels = torch.zeros(num_train,1,H,W,D).pin_memory()\n",
    "            for i,case in tqdm(enumerate(cases),total=num_train):\n",
    "                labels[i] = torch.from_numpy(nib.load(f'data_compressed/AbdomenCTCT/labelsTr/AbdomenCTCT_{case}_0000.nii.gz').get_fdata()).long().unsqueeze(0)\n",
    "\n",
    "        elif split == 'val_pred':\n",
    "            mode = 'Tr'\n",
    "            cases = [str(x).zfill(4) for x in list(range(31)[1::3])]\n",
    "            num_train=len(cases)\n",
    "            labels = torch.zeros(num_train,num_labels,H//2,W//2,D//2).pin_memory()\n",
    "            for i,case in tqdm(enumerate(cases),total=num_train):\n",
    "                labels[i] = F.avg_pool3d(F.one_hot(torch.from_numpy(nib.load(f'data_compressed/AbdomenCTCT/predictedlabelsTr/AbdomenCTCT_{case}_0000.nii.gz').get_fdata()).long().unsqueeze(0),num_labels).permute(0,4,1,2,3),2)\n",
    "\n",
    "    elif task_name == 'AMOS':\n",
    "        with open('data_compressed/AMOS/AMOS_dataset.json') as f:\n",
    "            dataset=json.load(f)\n",
    "\n",
    "        image_shape=dataset['tensorImageShape']['0']\n",
    "        num_labels=len(dataset['labels']['0'])\n",
    "        H,W,D=image_shape\n",
    "        lst = ['0507', '0508', '0510', '0514', '0517', '0518', '0522', '0530', '0532', '0538', '0540', '0541', '0551', '0555', '0557', '0571', '0578', '0580', '0582', '0584', '0585', '0586', '0587', '0588', '0589', '0590', '0592', '0594', '0595', '0596', '0597', '0599']\n",
    "        if split == 'train':\n",
    "            mode = 'Tr'\n",
    "            cases = lst [:-6]\n",
    "            num_train=len(cases)\n",
    "            labels = torch.zeros(num_train,num_labels,H//2,W//2,D//2).pin_memory()\n",
    "            for i,case in tqdm(enumerate(cases),total=num_train):\n",
    "                labels[i] = F.avg_pool3d(F.one_hot(torch.from_numpy(nib.load(f'data_compressed/AMOS/labelsTr/AMOS_{case}_0000.nii.gz').get_fdata()).long().unsqueeze(0),num_labels).permute(0,4,1,2,3),2)\n",
    "        \n",
    "        elif split == 'val':\n",
    "            mode = 'Tr'\n",
    "            cases = lst [-6:]\n",
    "            num_train=len(cases)\n",
    "            labels = torch.zeros(num_train,1,H,W,D).pin_memory()\n",
    "            for i,case in tqdm(enumerate(cases),total=num_train):\n",
    "                labels[i] = torch.from_numpy(nib.load(f'data_compressed/AMOS/labelsTr/AMOS_{case}_0000.nii.gz').get_fdata()).long().unsqueeze(0)\n",
    "\n",
    "        elif split == 'val_pred':\n",
    "            mode = 'Tr'\n",
    "            cases = lst [-6:]\n",
    "            num_train=len(cases)\n",
    "            labels = torch.zeros(num_train,num_labels,H//2,W//2,D//2).pin_memory()\n",
    "            mappingtensor = torch.LongTensor([ 0, 12, 11,  8,  0,  0,  0, 13,  5,  4,  9,  3,  2,  6, 10,  1,  7])\n",
    "            for i,case in tqdm(enumerate(cases),total=num_train):\n",
    "                labels[i] = F.avg_pool3d(F.one_hot(mappingtensor[torch.from_numpy(nib.load(f'data_compressed/AMOS_pred/predictedlabelsTr/AMOS_{case}_0000.nii.gz').get_fdata()).long()].unsqueeze(0),num_labels).permute(0,4,1,2,3),2)\n",
    "\n",
    "    \n",
    "    elif task_name == 'TS_Skeletal':\n",
    "\n",
    "        list_data=sorted(glob.glob(f'data_compressed/TS_Skeletal/labels/*nii.gz'))\n",
    "        if split == 'train':\n",
    "            cases = list_data#list_data[:27]\n",
    "            num_train,num_labels,H,W,D = (len(cases),29,256,160,256)\n",
    "            labels = torch.zeros(num_train,num_labels,H//2,W//2,D//2).pin_memory()\n",
    "            for i,case in tqdm(enumerate(cases),total=num_train):\n",
    "                labels[i] = F.avg_pool3d(F.one_hot(torch.from_numpy(nib.load(case).get_fdata()).long().unsqueeze(0),num_labels).permute(0,4,1,2,3),2)\n",
    "\n",
    "        elif split == 'val':\n",
    "            cases = list_data[27:]\n",
    "            num_train,num_labels,H,W,D = (len(cases),29,256,160,256)\n",
    "            labels = torch.zeros(num_train,1,H,W,D).pin_memory()\n",
    "            for i,case in tqdm(enumerate(cases),total=num_train):\n",
    "                labels[i] = torch.from_numpy(nib.load(case).get_fdata()).long().unsqueeze(0)\n",
    "\n",
    "        elif split == 'val_pred':\n",
    "            cases = list_data[27:]\n",
    "            num_train,num_labels,H,W,D = (len(cases),29,256,160,256)\n",
    "            labels = torch.zeros(num_train,num_labels,H//2,W//2,D//2).pin_memory()\n",
    "            for i,case in tqdm(enumerate(cases),total=num_train):\n",
    "                labels[i] = F.avg_pool3d(F.one_hot(torch.from_numpy(nib.load(case).get_fdata()).long().unsqueeze(0),num_labels).permute(0,4,1,2,3),2)\n",
    "\n",
    "    elif task_name == 'SilverCorpus':\n",
    "        mappingtensor =torch.LongTensor([0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 5, 6, 7, 8, 9, 0, 0, 0, 0, 0, 0,\n",
    "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4,\n",
    "        4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "        0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "\n",
    "        mapping_dict={\n",
    "        \"inferior_vena_cava\" : 2,\n",
    "        \"aorta\" : 1,\n",
    "        \"pulmonary_artery\" : 3,\n",
    "        \"heart_myocardium\": 4,\n",
    "        \"heart_atrium_left\": 4,\n",
    "        \"heart_ventricle_left\": 4,\n",
    "        \"heart_atrium_right\": 4,\n",
    "        \"heart_ventricle_right\":4,\n",
    "        \"lung_upper_lobe_left\":5,\n",
    "        \"lung_lower_lobe_left\":6,\n",
    "        \"lung_upper_lobe_right\":7,\n",
    "        \"lung_middle_lobe_right\":8,\n",
    "        \"lung_lower_lobe_right\":9\n",
    "        }\n",
    "\n",
    "        if split == 'train':\n",
    "            cases = [12, 36, 49, 68, 97]+[13, 24, 26, 27, 28, 29, 31, 32, 33, 34, 35, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 53, 54, 55, 57, 58, 59, 60, 62, 64, 65, 69, 70, 71, 72, 75, 76, 77, 78, 84, 91, 93, 98, 141]\n",
    "            num_train,num_labels,H,W,D = (len(cases),mappingtensor.max().item()+1,256,192,288)\n",
    "            labels = torch.zeros(num_train,num_labels,H//2,W//2,D//2).pin_memory()\n",
    "            for i,case in tqdm(enumerate(cases),total=num_train):\n",
    "                case_ = f'data_compressed/SilverCorpus/silver{str(case).zfill(3)}.nii.gz'\n",
    "                labels[i] = F.avg_pool3d(F.one_hot(mappingtensor[torch.from_numpy(nib.load(case_).get_fdata()).long().unsqueeze(0)],num_labels).permute(0,4,1,2,3),2)\n",
    "\n",
    "        if split == 'val':\n",
    "            cases = [12, 36, 49, 68, 97]\n",
    "            num_train,num_labels,H,W,D = (len(cases),mappingtensor.max().item()+1,256,192,288)\n",
    "            labels = torch.zeros(num_train,num_labels,H,W,D).pin_memory()\n",
    "            for i,case in tqdm(enumerate(cases),total=num_train):\n",
    "                case_ = f'data_compressed/SilverCorpus/silver{str(case).zfill(3)}.nii.gz'\n",
    "                labels[i] = mappingtensor[torch.from_numpy(nib.load(case_).get_fdata()).long().unsqueeze(0)]\n",
    "            \n",
    "        if split == 'val_pred':\n",
    "            cases = [12, 36, 49, 68, 97]\n",
    "            num_train,num_labels,H,W,D = (len(cases),mappingtensor.max().item()+1,256,192,288)\n",
    "            labels = torch.zeros(num_train,num_labels,H//2,W//2,D//2).pin_memory()\n",
    "            for i,case in tqdm(enumerate(cases),total=num_train):\n",
    "                case_ = f'data_compressed/SilverCorpus/silver{str(case).zfill(3)}.nii.gz'\n",
    "                labels[i] = F.avg_pool3d(F.one_hot(mappingtensor[torch.from_numpy(nib.load(case_).get_fdata()).long().unsqueeze(0)],num_labels).permute(0,4,1,2,3),2)\n",
    "\n",
    "\n",
    "    print('loaded', task_name, split)   \n",
    "    return labels, (num_train,num_labels,H,W,D)\n",
    "\n",
    "def get_val_pairs(B):\n",
    "    ii_all = torch.empty(0,2).long()\n",
    "    for i in range(B):\n",
    "        for j in range(B):\n",
    "            if(i<j):\n",
    "                ii_all = torch.cat((ii_all,torch.tensor([i,j]).long().view(1,2)),0)\n",
    "    return ii_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdamReg(mind_fix,mind_mov,dense_flow):\n",
    "\n",
    "    \n",
    "    if(dense_flow.shape[-1]==3):\n",
    "        dense_flow = dense_flow.permute(0,4,1,2,3)\n",
    "    \n",
    "    H,W,D = dense_flow[0,0].shape\n",
    "    \n",
    "    disp_hr = dense_flow.cuda().flip(1)*torch.tensor([H-1,W-1,D-1]).cuda().view(1,3,1,1,1)/2\n",
    "    with torch.enable_grad(): \n",
    "        grid_sp = 2\n",
    "\n",
    "       \n",
    "        disp_lr = F.interpolate(disp_hr,size=(H//grid_sp,W//grid_sp,D//grid_sp),mode='trilinear',align_corners=False)\n",
    "        net = nn.Sequential(nn.Conv3d(3,1,(H//grid_sp,W//grid_sp,D//grid_sp),bias=False))\n",
    "        net[0].weight.data[:] = disp_lr.float().cpu().data/grid_sp\n",
    "        net.cuda()\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=1)\n",
    "        grid0 = F.affine_grid(torch.eye(3,4).unsqueeze(0).cuda(),(1,1,H//grid_sp,W//grid_sp,D//grid_sp),align_corners=False)\n",
    "        #run Adam optimisation with diffusion regularisation and B-spline smoothing\n",
    "        lambda_weight = .65\n",
    "        for iter in range(50):\n",
    "            optimizer.zero_grad()\n",
    "            disp_sample = F.avg_pool3d(F.avg_pool3d(F.avg_pool3d(net[0].weight,3,stride=1,padding=1),3,stride=1,padding=1),\\\n",
    "                                       3,stride=1,padding=1).permute(0,2,3,4,1)\n",
    "            reg_loss = lambda_weight*((disp_sample[0,:,1:,:]-disp_sample[0,:,:-1,:])**2).mean()+\\\n",
    "            lambda_weight*((disp_sample[0,1:,:,:]-disp_sample[0,:-1,:,:])**2).mean()+\\\n",
    "            lambda_weight*((disp_sample[0,:,:,1:]-disp_sample[0,:,:,:-1])**2).mean()\n",
    "            scale = torch.tensor([(H//grid_sp-1)/2,(W//grid_sp-1)/2,(D//grid_sp-1)/2]).cuda().unsqueeze(0)\n",
    "            grid_disp = grid0.view(-1,3).cuda().float()+((disp_sample.view(-1,3))/scale).flip(1).float()\n",
    "            patch_mov_sampled = F.grid_sample(mind_mov.cuda().float(),grid_disp.view(1,H//grid_sp,W//grid_sp,D//grid_sp,3).cuda()\\\n",
    "                                              ,align_corners=False,mode='bilinear')\n",
    "            sampled_cost = (patch_mov_sampled-mind_fix.cuda()).pow(2).mean(1)*12\n",
    "            loss = sampled_cost.mean()\n",
    "            (loss+reg_loss).backward()\n",
    "            optimizer.step()\n",
    "        fitted_grid = disp_sample.permute(0,4,1,2,3).detach()\n",
    "        disp_hr = F.interpolate(fitted_grid*grid_sp,size=(H,W,D),mode='trilinear',align_corners=False)\n",
    "        \n",
    "    disp_smooth = F.avg_pool3d(F.avg_pool3d(F.avg_pool3d(disp_hr,3,padding=1,stride=1),3,padding=1,stride=1),3,padding=1,stride=1)\n",
    "\n",
    "\n",
    "    disp_hr = torch.flip(disp_smooth/torch.tensor([H-1,W-1,D-1]).view(1,3,1,1,1).cuda()*2,[1])\n",
    "    return disp_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks=['SilverCorpus','TS_Skeletal']\n",
    "\n",
    "results={}\n",
    "for task in tasks:\n",
    "    results[task]={}\n",
    "\n",
    "train_label = []; train_shapes = []\n",
    "iterate_list = [train_label, train_shapes]\n",
    "\n",
    "for t in tasks:\n",
    "    data=load_dataset_seg(t,split='train')\n",
    "    for x, lst in zip(data, iterate_list):\n",
    "        lst.append(x)\n",
    "\n",
    "\n",
    "val_label = []; val_shapes = []\n",
    "iterate_list = [val_label, val_shapes]\n",
    "\n",
    "for t in tasks:\n",
    "    data=load_dataset_seg(t,split='val')\n",
    "    for x, lst in zip(data, iterate_list):\n",
    "        lst.append(x)\n",
    "\n",
    "\n",
    "pred_label = []; pred_shapes = []\n",
    "iterate_list = [pred_label, pred_shapes]\n",
    "for t in tasks:\n",
    "    data=load_dataset_seg(t,split='val_pred')\n",
    "    for x, lst in zip(data, iterate_list):\n",
    "        lst.append(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edt_train_label=[]\n",
    "for dataset,task in enumerate(tasks):\n",
    "    B,num_classes,H,W,D = train_label[dataset].shape\n",
    "\n",
    "    tmp=torch.zeros(B,1,H,W,D)\n",
    "    for i in tqdm(range(B)):\n",
    "        for ii in range(num_classes):\n",
    "            edt = torch.from_numpy(distance_transform_edt((train_label[dataset][i,ii]).cpu().squeeze())).float()\n",
    "            tmp[i,0]+=edt#(7-nn.ELU()(7-edt))/7\n",
    "    edt_train_label.append(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1 not in skip_stage:\n",
    "    model = RegModel(1)\n",
    "\n",
    "    model.cuda()\n",
    "    repeats = 3\n",
    "    iterations =2000\n",
    "    run_dataset=torch.randint(0,len(tasks),[repeats,iterations])\n",
    "\n",
    "    for repeat in range(repeats):\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "        scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "        ramp_up = torch.sigmoid(torch.linspace(-5,25,iterations))\n",
    "\n",
    "        run_loss = torch.zeros(iterations,2)\n",
    "        run_val = torch.zeros(iterations//10)\n",
    "        t0 = time.time()\n",
    "        \n",
    "        with trange(iterations) as pbar:\n",
    "            for i in pbar:     \n",
    "                optimizer.zero_grad()\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    \n",
    "                    dataset=run_dataset[repeat,i]\n",
    "                    B,C,H,W,D = train_shapes[dataset]\n",
    "                    ii = torch.randperm(B)[:2]\n",
    "\n",
    "                    grid = F.affine_grid(torch.eye(3,4).unsqueeze(0).cuda(),(1,1,H//2,W//2,D//2)).cuda()\n",
    "                    \n",
    "                    affine = F.affine_grid((.07*ramp_up[i]*torch.randn(1,3,4)+torch.eye(3,4).unsqueeze(0)).cuda(),(1,1,H//2,W//2,D//2),align_corners=False)\n",
    "                    fix_aff = F.grid_sample(edt_train_label[dataset][ii[:1]].cuda(),affine,align_corners=False)\n",
    "                    fix_aff_img =  F.grid_sample(train_label[dataset][ii[:1]].cuda(),affine,align_corners=False)\n",
    "\n",
    "                    disp = model(fix_aff,edt_train_label[dataset][ii[1:2]].cuda(),level=int(i>iterations//2)+1)\n",
    "                    warped_img = F.grid_sample(train_label[dataset][ii[1:2]].cuda(),grid+disp.permute(0,2,3,4,1),padding_mode='border',align_corners=False)\n",
    "                    loss = (1-soft_dice(fix_aff_img,warped_img)).mean()\n",
    "                scaler.scale(loss).backward()\n",
    "                #scaler.unscale_(optimizer)\n",
    "                #torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                run_loss[i,0] = (1-soft_dice(fix_aff_img,train_label[dataset][ii[1:2]].cuda())).mean()\n",
    "                run_loss[i,1] = loss.item()\n",
    "\n",
    "                str1 = f\"d: {dataset.item()}, iter: {i}, loss: {'%0.3f'%run_loss[i-25:i-1,1].mean()} | {'%0.3f'%run_loss[i-25:i-1,0].mean()}, runtime: {'%0.1f'%(time.time()-t0)} sec, gpumem/max: {'%0.2f'%(torch.cuda.max_memory_allocated()*1e-9)} GB\"\n",
    "                pbar.set_description(str1)\n",
    "                        #print('dice',dice_val)\n",
    "\n",
    "        print(f\"Repeat {repeat}, Last 100 Losses {'%0.3f'%run_loss[i-101:i-1,1].mean()}\")\n",
    "        plt.plot(F.avg_pool1d(F.avg_pool1d(run_loss.view(1,1,-1),15,stride=3),15,stride=1).squeeze())\n",
    "\n",
    "    torch.save(model,f'unpaired_models/v2_{tasks[0]}_{tasks[1]}_edt_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 2 not in skip_stage:\n",
    "    model=torch.load(f'unpaired_models/v2_{tasks[0]}_{tasks[1]}_edt_model.pth').cuda()\n",
    "\n",
    "    adapt=ShufflePermutation().cuda()\n",
    "    model.train(); adapt.train()\n",
    "\n",
    "\n",
    "    repeats = 3\n",
    "    iterations = 2000\n",
    "    run_dataset=torch.randint(0,len(tasks),[repeats,iterations])\n",
    "\n",
    "\n",
    "    for repeat in range(repeats):\n",
    "\n",
    "        optimizer = torch.optim.Adam(list(model.parameters())+list(adapt.parameters()),lr=0.001)\n",
    "        scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "        ramp_up = torch.sigmoid(torch.linspace(-5,25,iterations))\n",
    "\n",
    "        run_loss = torch.zeros(iterations,2)\n",
    "        run_val = torch.zeros(iterations//10)\n",
    "        t0 = time.time()\n",
    "        \n",
    "        with trange(iterations) as pbar:\n",
    "            for i in pbar:     \n",
    "                optimizer.zero_grad()\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    \n",
    "                    dataset=run_dataset[repeat,i]\n",
    "\n",
    "                    B,C,H,W,D = train_shapes[dataset]\n",
    "                    ii = torch.randperm(B)[:2]\n",
    "                    grid = F.affine_grid(torch.eye(3,4).unsqueeze(0).cuda(),(1,1,H//2,W//2,D//2)).cuda()\n",
    "                    \n",
    "                    affine = F.affine_grid((.07*ramp_up[i]*torch.randn(1,3,4)+torch.eye(3,4).unsqueeze(0)).cuda(),(1,1,H//2,W//2,D//2),align_corners=False)\n",
    "                    fix_aff = F.grid_sample((train_label[dataset][ii[:1]].cuda()),affine,align_corners=False)\n",
    "                    fix_aff_img =  F.grid_sample(train_label[dataset][ii[:1]].cuda(),affine,align_corners=False)\n",
    "\n",
    "                    disp = model(adapt(fix_aff),adapt(train_label[dataset][ii[1:2]].cuda()),level=int(i>iterations//2)+1)\n",
    "                    #warped = F.grid_sample(train_label[dataset][ii[1:2]].cuda(),grid+disp.permute(0,2,3,4,1),padding_mode='border',align_corners=False)\n",
    "                    warped_img = F.grid_sample(train_label[dataset][ii[1:2]].cuda(),grid+disp.permute(0,2,3,4,1),padding_mode='border',align_corners=False)\n",
    "                    loss = (1-soft_dice(fix_aff_img,warped_img)).mean()\n",
    "                scaler.scale(loss).backward()\n",
    "                #scaler.unscale_(optimizer)\n",
    "                #torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                run_loss[i,0] = (1-soft_dice(fix_aff_img,train_label[dataset][ii[1:2]].cuda())).mean()\n",
    "                run_loss[i,1] = loss.item()\n",
    "\n",
    "                str1 = f\"d: {dataset.item()}, iter: {i}, loss: {'%0.3f'%run_loss[i-25:i-1,1].mean()} | {'%0.3f'%run_loss[i-25:i-1,0].mean()}, runtime: {'%0.1f'%(time.time()-t0)} sec, gpumem/max: {'%0.2f'%(torch.cuda.max_memory_allocated()*1e-9)} GB\"\n",
    "                pbar.set_description(str1)\n",
    "\n",
    "        print(f\"Repeat {repeat}, Last 100 Losses {'%0.3f'%run_loss[i-101:i-1,1].mean()}\")\n",
    "        plt.plot(F.avg_pool1d(F.avg_pool1d(run_loss.view(1,1,-1),15,stride=3),15,stride=1).squeeze())\n",
    "\n",
    "    torch.save([model,adapt],f'unpaired_models/v2_{tasks[0]}_{tasks[1]}_adapt_model.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ea7b25c166a17916b076a2f2c2a4306ef4fff6630470fa2690364fd40048f96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
